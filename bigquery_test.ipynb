{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23adcc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy matplotlib seaborn plotly scipy statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef783104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Environment Setup\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from typing import List\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "# regression analysis\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "client = bigquery.Client(project='moloco-ods')\n",
    "def process_query(input_query):\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    query_job = client.query(input_query, job_config=job_config)\n",
    "    df_return = query_job.result().to_dataframe()\n",
    "    return df_return\n",
    "\n",
    "def process_query_be(input_query):\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    query_job = client.query(input_query, job_config=job_config)\n",
    "    print(f\"Submitted job: {query_job.job_id}\")\n",
    "    return query_job\n",
    "\n",
    "def fetch_result(query_job):\n",
    "    \"\"\"\n",
    "    Return DataFrame only if the query is complete and successful.\n",
    "    If still running, return None.\n",
    "    If failed, return a dict with error info (so next loop can still check other jobs).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if query_job.done():\n",
    "            if query_job.error_result:\n",
    "                # Query finished but failed\n",
    "                print(f\"Job {query_job.job_id} failed: {query_job.error_result}\")\n",
    "                return {\"status\": \"error\", \"job_id\": query_job.job_id, \"error\": query_job.error_result}\n",
    "            else:\n",
    "                # Query finished successfully\n",
    "                print(f\"Job {query_job.job_id} is complete!\")\n",
    "                df_return = query_job.result().to_dataframe()\n",
    "                return {\"status\": \"success\", \"job_id\": query_job.job_id, \"data\": df_return}\n",
    "        else:\n",
    "            # Query still running\n",
    "            print(f\"Job {query_job.job_id} is still running...\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        # Unexpected error while fetching results\n",
    "        print(f\"Job {query_job.job_id} raised an exception: {e}\")\n",
    "        return {\"status\": \"exception\", \"job_id\": query_job.job_id, \"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cdc5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title data pull\n",
    "\n",
    "## start date and end date, target quarters (2 consecutive qurters)\n",
    "start_date = '2025-07-01'\n",
    "end_date = '2025-12-31'\n",
    "tgt_quarters = ['Q3','Q4']\n",
    "\n",
    "query = f\"\"\"\n",
    "\n",
    "  WITH market AS (\n",
    "    SELECT\n",
    "        (FORMAT_DATE('%Y-%m', DATE_TRUNC(fact_market.install_date_utc , QUARTER))) AS date_utc_quarter,\n",
    "        fact_market.migrated_platform  AS platform_id,\n",
    "        SAFE_DIVIDE(COALESCE(SUM(fact_market.moloco.revenue_d7 ), 0), COALESCE(SUM(fact_market.moloco.revenue_d7 ), 0) + COALESCE(SUM(fact_market.non_moloco.revenue_d7 ), 0)) AS share_of_revenue_d7\n",
    "    FROM `ads-bpd-guard-china.market_share.fact_market`  AS fact_market\n",
    "    WHERE ((( fact_market.install_date_utc  ) >= (DATE('{start_date}')) AND ( fact_market.install_date_utc  ) <= (DATE('{end_date}'))))\n",
    "      AND (fact_market.office ) = 'KOR'\n",
    "    GROUP BY\n",
    "        1,\n",
    "        2\n",
    "  ),\n",
    "\n",
    "  spend AS (\n",
    "    SELECT\n",
    "        (FORMAT_TIMESTAMP('%Y-%m', TIMESTAMP_TRUNC(TIMESTAMP(fact_dsp_core.date_utc) , QUARTER))) AS date_utc_quarter,\n",
    "        fact_dsp_core.platform_id  AS platform_id,\n",
    "        COALESCE(SUM(fact_dsp_core.gross_spend_usd ), 0) AS spend\n",
    "    FROM `ads-bpd-guard-china.athena.fact_dsp_core` fact_dsp_core\n",
    "    WHERE ((( TIMESTAMP(fact_dsp_core.date_utc)  ) >= (TIMESTAMP('{start_date} 00:00:00')) AND ( TIMESTAMP(fact_dsp_core.date_utc)  ) < (TIMESTAMP('{end_date} 00:00:00'))))\n",
    "      AND (fact_dsp_core.advertiser.office ) = 'KOR'\n",
    "    GROUP BY\n",
    "        1,\n",
    "        2\n",
    "      HAVING spend > 0\n",
    "  )\n",
    "\n",
    "  SELECT\n",
    "    *\n",
    "  FROM spend LEFT JOIN market USING(platform_id, date_utc_quarter)\n",
    "  ORDER BY platform_id, date_utc_quarter\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5de817fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please install the 'pandas' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/cloud/bigquery/_pandas_helpers.py:39\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     41\u001b[39m     pandas_import_exception = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mprocess_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df.head()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mprocess_query\u001b[39m\u001b[34m(input_query)\u001b[39m\n\u001b[32m     33\u001b[39m job_config = bigquery.QueryJobConfig()\n\u001b[32m     34\u001b[39m query_job = client.query(input_query, job_config=job_config)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m df_return = \u001b[43mquery_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df_return\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/cloud/bigquery/table.py:2597\u001b[39m, in \u001b[36mRowIterator.to_dataframe\u001b[39m\u001b[34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[39m\n\u001b[32m   2362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_dataframe\u001b[39m(\n\u001b[32m   2363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2364\u001b[39m     bqstorage_client: Optional[\u001b[33m\"\u001b[39m\u001b[33mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2383\u001b[39m     ] = DefaultPandasDTypes.RANGE_TIMESTAMP_DTYPE,\n\u001b[32m   2384\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mpandas.DataFrame\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2385\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[32m   2386\u001b[39m \n\u001b[32m   2387\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2595\u001b[39m \n\u001b[32m   2596\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     \u001b[43m_pandas_helpers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2599\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2600\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/cloud/bigquery/_pandas_helpers.py:1115\u001b[39m, in \u001b[36mverify_pandas_imports\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mverify_pandas_imports\u001b[39m():\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pandas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas_import_exception\u001b[39;00m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1117\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Please install the 'pandas' package to use this function."
     ]
    }
   ],
   "source": [
    "df = process_query(query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c710bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
